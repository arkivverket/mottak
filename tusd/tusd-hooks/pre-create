#!/usr/bin/env python3
import os                               # for getenv
import sys
import json
import psycopg2
import psycopg2.extras
import string
import subprocess
# For python 3.6
from subprocess import PIPE
import re  # for parsing the DBSTRING

import logging

from azure.servicebus import QueueClient, Message
from azure.servicebus.common.constants import ReceiveSettleMode
try:
    from dotenv import load_dotenv
    load_dotenv()
except:
    print('dotenv not loaded')

# Todo:
# - check that the uploader URL has not been tampered with
# - code can be cleaned up a bit.

# Return codes.
UUIDERROR = 1  # invalid UUID
DBERROR = 10
JSONERROR = 11
IOERROR = 12
USAGEERROR = 13
ARGOERROR = 14
UNKNOWNUUID = 15
UNKNOWNIID = 16


# There needs to be a envir variable called DBSTRING
# it is on the following format:

# 'pgsql:host=10.0.0.0;dbname=foo;user=myuser;password=verydull'


def create_db_access(dbstring):
    """Create a psycopg2 compatible object from the connection string.
    The string is from PHP and we reuse it here
    """
    mystr = dbstring[6:]
    mystr = mystr.rstrip()
    d = dict(re.findall(r'(\w+)=([^;]+);?', mystr))
    # Validate dbstring:
    for key in ['user', 'password', 'host', 'dbname']:
        if key not in d.keys():
            logging.error('%s not found in DBSTRING' % key)
            exit(DBERROR)
    return d


def my_connect(conn_info):
    try:
        connection = psycopg2.connect(user=conn_info['user'],
                                      host=conn_info['host'],
                                      dbname=conn_info['dbname'],
                                      password=conn_info['password'],
                                      sslmode='require',
                                      sslrootcert='BaltimoreCyberTrustRoot.crt.pem',
                                      connect_timeout=10)

    except (Exception, psycopg2.Error) as error:
        logging.error(f"Error while connecting to PostgreSQL: {error}")
        exit(DBERROR)
    finally:
        return connection


def my_disconnect(conn):
    conn.close()


def read_tusd_event(step):
    try:
        data = json.load(sys.stdin)
    except ValueError as e:
        logging.error(f"Error parsing JSON({step}): {e}")
        exit(JSONERROR)
    # Enable this when debugging the events. It dumps the input to /tmp so you can re-run the hook with stdin.
    with open(f'/tmp/json-event-{step}.json', 'w') as event_file:
        json.dump(data, event_file)

    return data


def get_metadata(conn, iid):
    try:
        dict_cursor = conn.cursor(
            cursor_factory=psycopg2.extras.RealDictCursor)
        dict_cursor.execute('SELECT invitations.id, uuid, checksum, is_sensitive, name, email, type '
                            'FROM invitations, archive_types '
                            'WHERE archive_type_id=archive_types.id '
                            'AND invitations.id=%s', (iid,))
        rec = dict_cursor.fetchall()
    except psycopg2.Error as e:
        logging.error(f'SQL Query error: {e}')
        exit(DBERROR)

    if len(rec) == 0:
        return None
    else:
        return rec[0]


def update_db_with_objectname(conn, iid, objectname):
    cur = conn.cursor()
    cur.execute(
        "UPDATE invitations SET object_name = %s WHERE id = %s", (objectname, iid))
    if cur.rowcount != 1:
        raise('Invalid number of rows updated')

def gather_params(metadata, data):
    """ create dict with the relevant data from the supplied dicts
     """
    # define en workflow parameters
    params = {
        'UUID': metadata['uuid'],
        'OBJECT': data['Upload']['Storage']['Key'],
        'CHECKSUM': metadata['checksum'],
        'ARCHIEVE_TYPE': metadata['type'],
        'NAME': metadata['name'],
        'EMAIL': metadata['email'],
        'INVITATIONID': metadata['id']
    }
    return params


def argo_submit(params):
    """ Submit a job to argo. Takes a dict with parameters. """

    message = {
        'action': 'argo-submit',
        'params': params,
    }
    queue_client = QueueClient.from_connection_string(
        os.getenv('AZ_SB_CON_KICKER'), os.getenv('AZ_SB_QUEUE') )

    with queue_client.get_sender() as sender:
        message = Message(json.dumps(message).encode('utf8'))
        logging.info(f'Sending message: {message}')
        ret = sender.send(message)


########################################################
############# Run from here  ###########################
########################################################

# We use the same source for both pre-create and post-finish hook
# This identifies it

logging.basicConfig(level=os.getenv('LOGLEVEL', 'INFO'))


my_name = os.path.basename(__file__)
logging.info(f'hook running as {my_name}')
tusd_data = read_tusd_event(step=my_name)


if not (os.getenv('DBSTRING')):
    logging.error("DBSTRING environment variable not set")
    exit(USAGEERROR)

try:
    iid = tusd_data["Upload"]["MetaData"]["invitation_id"]
    logging.info(f"Invitation ID from JSON: {iid}")
    # todo: Specify exception.
except:
    logging.error(f"Could not find invitation_id in JSON: {iid}")
    exit(UNKNOWNIID)


connection = my_connect(create_db_access(os.getenv('DBSTRING')))

metadata = get_metadata(connection, iid)
if (metadata == None):
    logging.error(
        f"Failed to fetch metadata for invitation {iid} - no invitation?")
    exit(UNKNOWNIID)

uuid = metadata['uuid']


# This is the pre-create hook. The only concern here is to validate the UUID
if (my_name == 'pre-create'):
    if not (uuid == metadata['uuid']):
        logging.error(f'Unknown UUID (db said {metadata["uuid"]} - tusd gave us {uuid}')
        exit(UUIDERROR)
    else:
        logging.info('Invitation ID verified.')
        exit(0)

# We assume that we're the post-create hook and we create an input-file for argo
# and submit the workflow into argo.

# Verify that we have a filename:
try:
    filename = tusd_data['Upload']['Storage']['Key']
    logging.debug(f"File name (in objectstore) is {filename}")
except:
    logging.error("Could not key/filename in JSON. Dumping JSON:")
    logging.error(json.dump(data))
    exit(JSONERROR)

try:
    update_db_with_objectname(connection, iid, filename)
    logging.debug(f"Set object_name to {filename} for iid {iid} in database.")
except Exception as e:
    logging.error("Error while updating database {e}")
    exit(DBERRROR)

if ((metadata) and ('uuid' in metadata)):
    # create_param_file(param_file, metadata, data)
    # Create a param dict based on data from DB and tusd
    params = gather_params(metadata, tusd_data)
    # Submit it the service bus.
    argo_submit(params)

    my_disconnect(connection)

    exit(0)
else:
    logging.error("Unknown UUID:" + uuid)
    exit(UUIDERROR)

